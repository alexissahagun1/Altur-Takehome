# Altur Call Analyzer ğŸ“ ğŸ¤–

A production-grade, full-stack application that transforms sales calls into actionable intelligence using OpenAI Whisper and GPT-4o.

![License](https://img.shields.io/badge/license-MIT-blue)
![Status](https://img.shields.io/badge/status-production-green)

## ğŸš€ Features

-   **ğŸ™ï¸ Audio Transcription**: High-fidelity transcription of WAV/MP3 files using `whisper-1`.
-   **ğŸ§  Intelligent Analysis**: Uses a **Chain-of-Thought** prompt with GPT-4o to extract:
    -   Executive Summary
    -   Sentiment Analysis (Score & Label)
    -   User Intent Classification
    -   Speaker Role Identification
    -   Key Actionable Insights
-   **ğŸ“Š Analytics Dashboard**: Visualizes call volume, sentiment trends, and top tags using Recharts.
-   **ğŸ·ï¸ Smart Tagging**: Auto-tagging by AI with manual user override capabilities.
-   **ğŸ’¾ Hybrid Persistence**: Supports both SQLite (local dev) and PostgreSQL (production/Supabase).
-   **â˜ï¸ Robust Deployment**: Dockerized "Monorepo-lite" deployed on Render (Backend) and Vercel (Frontend).

---

## ğŸ—ï¸ Architecture & Design Decisions

This project follows a **Monorepo-lite** structure, keeping the Frontend and Backend in a single repository for easier coordination while maintaining clear separation of concerns.

### 1. Backend: Layered FastAPI Service
We chose **FastAPI** for its speed and native Pydantic integration.
-   **API Layer (`main.py`)**: Handles routing and request validation.
-   **Logic Layer (`services.py`)**: Contains the core business logic. We use a **"Fat Service, Thin Controller"** pattern.
    -   *Trade-off*: We process files synchronously for simplicity, but for a larger scale, we would use a task queue (Celery/Redis) to handle long transcriptions.
-   **Data Layer (`models.py`)**: We use a **JSON Column** for the analysis results.
    -   *Why?* AI outputs are unpredictable and evolve fast. A JSON column allows us to add new fields (e.g., "objection_handling_score") without running complex database migrations.

### 2. Frontend: Next.js 15 App Router
-   **Server Components**: heavily used for data fetching to reduce client-side JavaScript and improve SEO/Performance.
-   **Tailwind CSS**: For rapid, responsive UI development.
-   **Error Handling**: Implemented graceful fallbacks (empty states, error toasts) if the API is unreachable.

### 3. AI Integration Strategy
-   **Chain-of-Thought Prompting**: Instead of making 5 separate API calls (one for summary, one for sentiment, etc.), we use a single, structured prompt that asks the LLM to "think" and output a single JSON object.
    -   *Benefit*: Reduces latency and OpenAI costs by ~80%.
-   **JSON Mode**: We enforce valid JSON output from GPT-4o to prevent parsing errors.

---

## ğŸ› ï¸ Tech Stack

| Component | Technology | Description |
| :--- | :--- | :--- |
| **Frontend** | Next.js 15, React 19, Tailwind | Modern, server-first UI. |
| **Backend** | Python 3.10, FastAPI, SQLAlchemy, Poetry | High-performance async API with robust dependency management. |
| **Database** | PostgreSQL (Supabase) | Robust relational data storage. |
| **AI** | OpenAI Whisper + GPT-4o | State-of-the-art transcription & reasoning. |
| **DevOps** | Docker, Docker Compose, Render, Vercel | Consistent environments & seamless cloud deployment. |

---

## ğŸƒâ€â™‚ï¸ How to Run

### Option A: Docker (Recommended)
1.  **Clone & Configure**:
    ```bash
    git clone <repo-url>
    cd altur-call-analyzer
    # Create .env file
    echo "OPENAI_API_KEY=sk-..." > .env
    echo "DATABASE_URL=postgresql://..." >> .env
    ```
2.  **Run**:
    ```bash
    docker compose up --build
    ```
3.  **Access (When Running Locally)**:
    -   Frontend: `http://localhost:3000`
    -   Uvicorn (backend) `http://0.0.0.0:8000`

### Option B: Local Development
**Backend**:
```bash
cd backend
poetry install
export OPENAI_API_KEY=sk-...
poetry run uvicorn backend.main:app --reload
```

**Frontend**:
```bash
cd frontend
npm install
npm run dev
```

---

## ğŸ§ª Testing

We include a suite of tests to verify API health and error handling.

```bash
# Run from the root directory
poetry install  # Installs dev dependencies like pytest
poetry run pytest
```

**What we test:**
-   âœ… Server Health Check
-   âœ… Database Connection
-   âœ… Invalid File Type Handling (Security)

---

## ğŸ† Evaluation Criteria Checklist

| Criterion | How We Met It |
| :--- | :--- |
| **Functionality** | Complete flow: Upload -> Whisper -> GPT-4 -> DB -> UI. |
| **Code Quality** | Modular `services.py`, typed Pydantic schemas, clean `api.ts` wrapper. |
| **AI Logic** | Structured JSON prompting, fallback "mock" modes for dev without keys. |
| **Documentation** | Comprehensive README, architecture explanation, setup guide. |
| **Tests** | Pytest suite for endpoints and error cases. |
| **UI/UX** | Upload progress bars, empty states, clean data visualization. |
| **Polish** | **Dockerized**, **Cloud Deployed**, **Export to JSON** feature added. |

---

## ğŸ”® Future Roadmap

To scale this from an MVP to a production SaaS, we have identified these high-impact improvements:

1.  **âš¡ Async Processing (Task Queues)**
    *   *Current*: Synchronous processing (can timeout on large files).
    *   *Future*: Implement **Celery + Redis** to handle long audio files in the background and notify the frontend via WebSockets.

2.  **ğŸ” Semantic Search (RAG)**
    *   *Current*: Keyword filtering by tag.
    *   *Future*: Use **pgvector** (Supabase) and OpenAI Embeddings to allow users to ask natural language questions like "Show me calls where the customer asked about pricing."

3.  **ğŸ¹ "Karaoke-Style" Interactive Player**
    *   *Current*: Static text transcript.
    *   *Future*: Use Whisper's timestamp data to highlight words in real-time as the audio plays.
